INSERT INTO `dm-condor-dev.condor_dev.task_prop_table` (task_name, is_filename_req_in_target, job_prop_table, target, transformation_table, data_quality_rule_table, additional_input, task_id, source_schema_validation, input_processor) VALUES ('cndr-1-testjsonbq-126-84-1232-o', 'False', STRUCT('dm-condor-dev.condor_dev.job_prop_table' AS table_id, 'cndr-1-testjsonbq-126-84-1232-o' AS job_name), STRUCT('dm-condor-dev.condor_dev.testjsonbq' AS target_table, NULL AS schema_file, 'WRITE_APPEND' AS write_disposition), NULL, NULL, PARSE_JSON('{"data_file": "gs://test", "targets": [{"bigquery": {"target_table": "dm-condor-dev.condor_dev.testjsonbq", "write_disposition": "WRITE_APPEND"}}]}'), 'CNDR_1_TESTJSONBQ_126_84', FALSE, 'JsonProcessor');INSERT INTO `dm-condor-dev.condor_dev.job_prop_table` (audit, error, input_processor, job_name, target_sys, source, additional_input, sub_source) VALUES (STRUCT('gs://{CODE_BUCKET}/python_df/CSVProcessor/audit/file_audit.json' AS file_audit_table_schema, '{GCP_PROJECT}.condor_dev.condor_ingestion_audit' AS job_audit_table, '{GCP_PROJECT}.condor_dev.file_audit' AS file_audit_table, FALSE AS enable_file_level_auditing, NULL AS job_audit_table_schema, 'bigquery' AS audit_target, TRUE AS required), STRUCT('gs://{CODE_BUCKET}/python_df/CSVProcessor/error/error_table.json' AS error_table_schema, 'WRITE_APPEND' AS error_table_write_disposition, '{GCP_PROJECT}:condor_dev.error_table' AS error_table, TRUE AS insert_error_rec), 'Object StorageProcessor', 'cndr-1-testjsonbq-126-84-1232-o', 'Bigquery', 'Object Storage', PARSE_JSON('{"license_endpoint": "172.16.128.18:8000"}'), 'Gcs-JSON');